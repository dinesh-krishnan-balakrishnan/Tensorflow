{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks: Structure\n",
    "\n",
    "Neural networks are meant to mimick the human brain in the sense that they use \"neurons\" to form connections and predictions from data, just as the brain uses neurons to take input from human senses and make future actions. By imitating the functionality of the brain and its decision making process, the _Neural Network_ model is also able to make various connections between independent variables and dependent variables. It is these connections that it will use to make predictions for future data. \n",
    "\n",
    "## The Neuron\n",
    "\n",
    "<img src=\"neuron.png\" width=\"500px;\" alt=\"Neuron Structure\" />\n",
    "\n",
    "A neuron is also referred to as a _node_. Each neuron accepts a series of independent variables to produce a single output variable, as shown by the yellow independent variables and the red output variable in the diagram above. The connection between the various elements is called a synapse, which is represented by the blue arrows. \n",
    "\n",
    "<img src=\"neuronProcess.png\" width=\"600px;\" alt=\"Neuron Functionality\" />\n",
    "\n",
    "It is required that all the independent variables are standardized or normalized. Standardization involves mathematically transforming a dataset to have a have a mean of 0 and variance of 1, while normalization involves fitting all values into a range between 0 and 1. Standardization and Normalization prevents independent variables that can have drastically high or low values from having too much influence over the output value. The neuron will then use the standardized independent variables and the variables' respective weight values from $w_1$ to $w_n$ as input for an *activation function*, the resulting value being the neuron's output.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## The Neural Network\n",
    "\n",
    "<img src=\"network.png\" width=\"600px;\" alt=\"Neural arrangement within a network.\" />\n",
    "\n",
    "A _Neural Network_ always consists of an input layer, zero or more hidden layers, and an output layer. In fact, computational learning that involves neural networks that have zero or one hidden layers is called _Shallow Learning_. This is because _Deep Learning_ often has many hidden layers that work together to create very intricate connections from input data. In the diagram above, each neuron in the hidden layer will get all the input variables from the input layer and the output neuron will get all the values from the hidden layer. If there was another hidden layer after the first, it would receive all output values from the first hidden layer. \n",
    "\n",
    "__Purpose of Structure:__ Through learning, each neuron in the hidden layer will make a connection between the input variables and the output. Each neuron will then change the weight for each input variable based on how the variable relates to the connection the neuron has formed. Variables that aren't affecting the output will be assigned a weight of zero. By having a network-like structure, many different connections between the input variables and output can be made for the trained model to make better judgements. Quite frequently, _Neural Networks_ find connections between the input and output that humans haven't recognized before. \n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Activation Functions\n",
    "\n",
    "Activation functions are used by neurons to make sense of the complicated functional mappings created by having various input variables. The value passed into the activation functions shall be called $x$, which is the sum of each independent variable times the variable's weight.\n",
    "\n",
    "$$\\large x = \\sum_{i = 1}^{n} {variable_i \\times w_i} $$\n",
    "\n",
    "\n",
    "There are many different activation functions suited for different scenarios, but here are 4 popular ones:\n",
    "\n",
    "### Threshold\n",
    "\n",
    "<img src=\"threshold.png\" width=\"600px;\" alt=\"Graph of the Threshold Function\" />\n",
    "\n",
    "Most likely the most simple one out of the four, the __Threshold Function__ will return:\n",
    "* 0: $x$ is less than 0 \n",
    "* 1: $x$ is greater than or equal to 0.\n",
    "\n",
    "### Sigmoid\n",
    "\n",
    "<img src=\"sigmoid.png\" width=\"600px;\" alt=\"Graph of the Sigmoid Function\" />\n",
    "\n",
    "The __Sigmoid Function__ is very useful as it transforms any $x$ into a value between 0 and 1. This is different from the __Threshold Function__ because the output value can be any value in the range (0, 1), creating the possibility to have a much more detailed output.   \n",
    "\n",
    "### Rectifier\n",
    "\n",
    "<img src=\"rectifier.png\" width=\"600px;\" alt=\"Graph of the Rectifier Function\" />\n",
    "\n",
    "The __Rectifier Function__ produces a value of 0 when $x$ is negative, but outputs the same value as $x$ when $x \\ge 0$.\n",
    "\n",
    "### Hyperbolic Tangent\n",
    "\n",
    "<img src=\"hyperbolic.png\" width=\"600px;\" alt=\"Graph of the Hyperbolic Tangent Function\" />\n",
    "\n",
    "The __Hyperbolic Tangent Function__ is very similar to the sigmoid function, except it outputs a value in the range (-1, 1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
